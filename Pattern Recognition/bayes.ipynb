{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import*\n",
    "from sklearn.preprocessing import StandardScaler #標準化\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "class Bayes:\n",
    "    def __init__(self, training_data, labels):\n",
    "        self.training_data = training_data\n",
    "        self.labels = labels\n",
    "        self.classes = np.unique(labels)\n",
    "        self.class_num = len(self.classes)\n",
    "        self.feature_num = training_data.shape[1]\n",
    "        self.means = np.zeros([self.class_num, self.feature_num])\n",
    "        self.variances = np.zeros([self.class_num, self.feature_num])\n",
    "        self.covariances = np.zeros([self.class_num, self.feature_num, self.feature_num])\n",
    "        self.priors = [0 for _ in range(self.class_num)]\n",
    "\n",
    "    def fit(self):\n",
    "        #calculate priors, means, variances\n",
    "        for i, c in enumerate(self.classes):\n",
    "            data_class = self.training_data[self.labels == c]\n",
    "            self.priors[i] = len(data_class) / len(self.training_data)\n",
    "            self.means[i] = np.mean(data_class, axis=0)\n",
    "            self.variances[i] = np.var(data_class, axis=0) + 1e-10\n",
    "            self.covariances[i] = np.cov(data_class, rowvar=False) + 1e-10 * np.eye(self.feature_num)\n",
    "    \n",
    "    def predict(self, testing_data):\n",
    "        likelihood = np.zeros([len(testing_data), self.class_num])\n",
    "\n",
    "        for i, c in enumerate(self.classes):\n",
    "            class_likelihood = stats.norm.pdf(testing_data, loc=self.means[i], scale=np.sqrt(self.variances[i]))\n",
    "            class_likelihood = np.prod(class_likelihood, axis=1)\n",
    "            likelihood[:, i] = class_likelihood * self.priors[i]\n",
    "        return self.classes[np.argmax(likelihood, axis=1)]\n",
    "\n",
    "    def score(self, testing_data, testing_labels):\n",
    "        pre_labels = self.predict(testing_data)\n",
    "        return np.sum([pre_labels[i] == testing_labels[i] for i in range(len(testing_data))]) / len(testing_data)\n",
    "\n",
    "    def bayes_error(self):\n",
    "        Opt_s = np.zeros([self.class_num, self.class_num])\n",
    "        Bayes_errors = [[float('-inf') for _ in range(self.class_num)] for _ in range(self.class_num)]\n",
    "        for i in range(self.class_num):\n",
    "            for j in range(i+1, self.class_num):\n",
    "                delta = self.means[j] - self.means[i]\n",
    "                for s in np.linspace(0, 1, 50):\n",
    "\n",
    "                    sigma = s * self.covariances[i] + (1-s) * self.covariances[j]\n",
    "                    sigma_inv = np.linalg.pinv(sigma)\n",
    "\n",
    "                    error = (((s * (1-s)) / 2) * np.matmul(np.matmul(delta.T, sigma_inv), delta) + 0.5 * np.log(np.linalg.det(sigma) / \n",
    "                            pow(np.linalg.det(self.covariances[i]), s) * pow(np.linalg.det(self.covariances[j]), (1-s))))\n",
    "                    if error > Bayes_errors[i][j]:\n",
    "                        Bayes_errors[i][j] = error\n",
    "                        Opt_s[i][j] = round(s, 4)\n",
    "                #計算錯誤率\n",
    "                Bayes_errors[i][j] = round(exp(-Bayes_errors[i][j]), 2)\n",
    "\n",
    "        return Opt_s, Bayes_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test \u001b[39m=\u001b[39m Bayes(train_data, train_labels)\n\u001b[0;32m      2\u001b[0m test\u001b[39m.\u001b[39mfit()\n\u001b[0;32m      4\u001b[0m S, Bayes_errors \u001b[39m=\u001b[39m test\u001b[39m.\u001b[39mbayes_error()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "test = Bayes(train_data, train_labels)\n",
    "test.fit()\n",
    "\n",
    "S, Bayes_errors = test.bayes_error()\n",
    "for i in range(test.class_num):\n",
    "    for j in range(i+1, test.class_num):\n",
    "        print(f\"{i} 與 {j} 的Chernoff bound為{S[i][j]}\")\n",
    "        print(f\"Bayes Error為{Bayes_errors[i][j]}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 1 + 1 +(\n",
    "    +1\n",
    ")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 2 2 2 1 1 1 2 2 1 3 2 2 1 2 3 3 1 2 2 3 1 1 1 2 1 3 3 1 1 1 2 2 1\n",
      " 1 3 1 3 3 1 1 3 3 1 2 2 2 3 3 1 1 2 1 2 2 2 2 1 1 2 1 3 1 1 2 2 3 3 3 2 2\n",
      " 3 3 3 2 1 2 2 3 1 3 1 3 3 2 2]\n",
      "[1 1 1 1 2 2 2 1 1 1 2 2 1 3 2 2 1 2 3 3 1 2 2 3 1 1 1 2 1 3 3 1 1 1 2 2 1\n",
      " 1 3 1 3 3 1 1 3 3 1 2 1 2 3 3 1 1 2 1 2 2 2 2 1 1 1 1 3 1 1 2 2 3 3 3 2 2\n",
      " 3 3 3 2 1 2 2 3 1 3 1 3 3 2 2]\n",
      "87\n",
      "0.9775280898876404\n"
     ]
    }
   ],
   "source": [
    "test = Bayes(train_data, train_labels)\n",
    "test.fit()\n",
    "pred = test.predict(test_data)\n",
    "score = test.score(test_data, test_labels)\n",
    "print(pred)\n",
    "print(test_labels)\n",
    "temp = []\n",
    "for i in range(len(pred)):\n",
    "    if pred[i] == test_labels[i]:\n",
    "        temp.append(1)\n",
    "    else:\n",
    "        temp.append(0)\n",
    "print(sum(temp))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 與 1 的 Chernoff bound 為 0.8163 Bayes Error 為 0.11%\n",
      "0 與 2 的 Chernoff bound 為 0.5306 Bayes Error 為 0.0%\n",
      "1 與 2 的 Chernoff bound 為 0.9388 Bayes Error 為 0.46%\n",
      "\n",
      "0 與 1 的 Chernoff bound 為 0.8571 Bayes Error 為 0.4%\n",
      "0 與 2 的 Chernoff bound 為 0.6531 Bayes Error 為 0.0%\n",
      "1 與 2 的 Chernoff bound 為 0.9388 Bayes Error 為 0.35%\n",
      "\n",
      "0 與 1 的 Chernoff bound 為 0.8571 Bayes Error 為 0.29%\n",
      "0 與 2 的 Chernoff bound 為 0.6531 Bayes Error 為 0.0%\n",
      "1 與 2 的 Chernoff bound 為 0.9388 Bayes Error 為 0.31%\n",
      "\n",
      "0 與 1 的 Chernoff bound 為 0.8776 Bayes Error 為 0.41%\n",
      "0 與 2 的 Chernoff bound 為 0.6531 Bayes Error 為 0.0%\n",
      "1 與 2 的 Chernoff bound 為 0.9184 Bayes Error 為 0.29%\n",
      "\n",
      "0 與 1 的 Chernoff bound 為 0.8367 Bayes Error 為 0.25%\n",
      "0 與 2 的 Chernoff bound 為 0.6939 Bayes Error 為 0.0%\n",
      "1 與 2 的 Chernoff bound 為 0.898 Bayes Error 為 0.15%\n",
      "\n",
      "0 與 1 的 Chernoff bound 為 0.8163 Bayes Error 為 0.12%\n",
      "0 與 2 的 Chernoff bound 為 0.7143 Bayes Error 為 0.0%\n",
      "1 與 2 的 Chernoff bound 為 0.9184 Bayes Error 為 0.29%\n",
      "\n",
      "0 與 1 的 Chernoff bound 為 0.8163 Bayes Error 為 0.23%\n",
      "0 與 2 的 Chernoff bound 為 0.5714 Bayes Error 為 0.0%\n",
      "1 與 2 的 Chernoff bound 為 0.9592 Bayes Error 為 0.85%\n",
      "\n",
      "0 與 1 的 Chernoff bound 為 0.8367 Bayes Error 為 0.3%\n",
      "0 與 2 的 Chernoff bound 為 0.5918 Bayes Error 為 0.0%\n",
      "1 與 2 的 Chernoff bound 為 0.9388 Bayes Error 為 0.51%\n",
      "\n",
      "0 與 1 的 Chernoff bound 為 0.7959 Bayes Error 為 0.04%\n",
      "0 與 2 的 Chernoff bound 為 0.6735 Bayes Error 為 0.0%\n",
      "1 與 2 的 Chernoff bound 為 0.9388 Bayes Error 為 0.69%\n",
      "\n",
      "0 與 1 的 Chernoff bound 為 0.8367 Bayes Error 為 0.16%\n",
      "0 與 2 的 Chernoff bound 為 0.5306 Bayes Error 為 0.0%\n",
      "1 與 2 的 Chernoff bound 為 0.8776 Bayes Error 為 0.28%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for _ in range(10):\n",
    "    #read data and data preprocessing\n",
    "    feature_names = ['label','Alcohol', 'Malic acid','Ash','Alcalinity of ash' ,'Magnesium',\n",
    "                    'Total phenols','Flavanoids','Nonflavanoid phenols','Proanthocyanins',\n",
    "                    'Color intensity','Hue','OD280/OD315 of diluted wines','Proline' ]\n",
    "\n",
    "    data = pd.read_csv(\"wine.txt\", names=feature_names)\n",
    "    data = data.sample(frac=1) \n",
    "\n",
    "    half = int(len(data) * 0.5)\n",
    "    train_data=data.iloc[:half]\n",
    "    test_data=data.iloc[half:]\n",
    "\n",
    "    train_labels = train_data.iloc[:,0].values\n",
    "    test_labels = test_data.iloc[:,0].values\n",
    "\n",
    "    train_data = train_data.drop('label', axis=1)\n",
    "    test_data = test_data.drop('label', axis=1)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    train_data = scaler.fit_transform(train_data.iloc[:, :])\n",
    "    test_data  = scaler.transform(test_data.iloc[:, :])\n",
    "\n",
    "    test = Bayes(train_data, train_labels)\n",
    "    test.fit()\n",
    "    pred = test.predict(test_data)\n",
    "    score = test.score(test_data, test_labels)\n",
    "    scores.append(round(score*100, 2))\n",
    "    S, Bayes_errors = test.bayes_error()\n",
    "    for i in range(test.class_num):\n",
    "        for j in range(i+1, test.class_num):\n",
    "            print(f\"{i} 與 {j} 的 Chernoff bound 為 {S[i][j]}\", end=\" \")\n",
    "            print(f\"Bayes Error 為 {Bayes_errors[i][j]}%\")\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1次結果：97.75%\n",
      "第2次結果：96.63%\n",
      "第3次結果：96.63%\n",
      "第4次結果：94.38%\n",
      "第5次結果：98.88%\n",
      "第6次結果：89.89%\n",
      "第7次結果：97.75%\n",
      "第8次結果：98.88%\n",
      "第9次結果：96.63%\n",
      "第10次結果：95.51%\n",
      "平均：96.29%\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(scores)):\n",
    "    print(f\"第{i+1}次結果：{scores[i]}%\")\n",
    "print(f\"平均：{round(np.mean(scores), 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 13)\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Last 2 dimensions of the array must be square",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(b\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      4\u001b[0m c \u001b[39m=\u001b[39m b[\u001b[39m0\u001b[39m]\u001b[39m-\u001b[39mb[\u001b[39m1\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49minv([c]))\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36minv\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\cocog\\anaconda3\\envs\\basic_env\\Lib\\site-packages\\numpy\\linalg\\linalg.py:533\u001b[0m, in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    531\u001b[0m a, wrap \u001b[39m=\u001b[39m _makearray(a)\n\u001b[0;32m    532\u001b[0m _assert_stacked_2d(a)\n\u001b[1;32m--> 533\u001b[0m _assert_stacked_square(a)\n\u001b[0;32m    534\u001b[0m t, result_t \u001b[39m=\u001b[39m _commonType(a)\n\u001b[0;32m    536\u001b[0m signature \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mD->D\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m isComplexType(t) \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39md->d\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\cocog\\anaconda3\\envs\\basic_env\\Lib\\site-packages\\numpy\\linalg\\linalg.py:190\u001b[0m, in \u001b[0;36m_assert_stacked_square\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    188\u001b[0m m, n \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:]\n\u001b[0;32m    189\u001b[0m \u001b[39mif\u001b[39;00m m \u001b[39m!=\u001b[39m n:\n\u001b[1;32m--> 190\u001b[0m     \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m'\u001b[39m\u001b[39mLast 2 dimensions of the array must be square\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Last 2 dimensions of the array must be square"
     ]
    }
   ],
   "source": [
    "a = test.variances.reshape(-1, 1)\n",
    "b = test.variances\n",
    "print(b.shape)\n",
    "c = b[0]-b[1]\n",
    "print(np.linalg.pinv([c]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
